# ðŸ¤– Simple Ollama Chat UI ðŸ¤–

This is a simple chat ui to run ollama models with focused for windows but I believe easily run on OS.
I grew tired of running models through the console and couldn't find another way that I liked! To note this
is very barebones, it does not currently support chat memory or have any pretty mathematical symbol formatting
like that found with chatGPT or another online one.

# Notes

Ollama needs to be running for the api request to work. Also you need to manually replace model name with your specific model at the top of the code.

# Install dependencies
pip install -r requirements.txt --> only external library is requests
