# ðŸ¤– Llm Chat UI ðŸ¤–

This is a simple chat ui to run ollama models with focused for windows but I believe easily run on OS.
I grew tired of running models through the console and couldn't find another way that I liked! To note this
is very barebones, it does not currently support chat memory or have any pretty mathematical symbol formatting
like that found with chatGPT or another online one.

# Install dependencies
pip install -r requirements.txt --> only external library is requests
